{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mbz/users/shibo.hao/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<｜User｜>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<｜tool▁call▁begin｜>' + tool['type'] + '<｜tool▁sep｜>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<｜tool▁call▁end｜>'}}{{'<｜tool▁calls▁end｜><｜end▁of▁sentence｜>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<｜tool▁outputs▁end｜>' + message['content'] + '<｜end▁of▁sentence｜>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<｜Assistant｜>' + content + '<｜end▁of▁sentence｜>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<｜tool▁output▁begin｜>' + message['content'] + '<｜tool▁output▁end｜>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<｜tool▁outputs▁end｜>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<｜Assistant｜><think>\\n'}}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the capital of the moon?\"\n",
    "        }\n",
    "    ],\n",
    "    add_generation_prompt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151644,\n",
       " 8948,\n",
       " 198,\n",
       " 2610,\n",
       " 525,\n",
       " 264,\n",
       " 10950,\n",
       " 17847,\n",
       " 13,\n",
       " 151645,\n",
       " 198,\n",
       " 151644,\n",
       " 872,\n",
       " 198,\n",
       " 3838,\n",
       " 374,\n",
       " 279,\n",
       " 6722,\n",
       " 315,\n",
       " 279,\n",
       " 17788,\n",
       " 30,\n",
       " 151645,\n",
       " 198,\n",
       " 151644,\n",
       " 77091,\n",
       " 198]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nWhat is the capital of the moon?<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(torch.tensor(inputs).unsqueeze(0).cuda(), max_new_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>What is the capital of the moon?<｜Assistant｜><think>\n",
      "Okay, so I'm trying to figure out the capital of the moon. Hmm, that's an interesting question. I know that on Earth, we have cities like New York and Tokyo, which are the capitals. But the moon is a celestial body, not a planet, so it doesn't have a capital in the traditional sense. Maybe the question is a play on words or something else.\n",
      "\n",
      "Let me think. The word \"moon\" has \"o\" as the second letter. If I capitalize that, it would become \" moons,\" but that doesn't make much sense. Maybe it's a trick question. Perhaps the answer is that there isn't a capital, or that the moon doesn't have one. Or maybe it's referencing something else, like a fictional city or a game.\n",
      "\n",
      "I should consider different interpretations. One possibility is that the question is asking about the capital of the Moon, which is a hypothetical planet. If it were a planet, it would be a city, but since it's a moon, perhaps the answer is that there isn't one. Alternatively, maybe it's a play on words where \"moon\" is capitalized as \" moons,\" but that's just a pun and not a real answer.\n",
      "\n",
      "Another angle could be that the moon is sometimes called the \"Eiffel Tower of the Moon,\" which is a fun name, but that doesn't give a capital. Or maybe it's referencing a different system of measurement where the capital is something else, but that seems unlikely.\n",
      "\n",
      "I should also think about whether there's any real-world reference to a city named after the moon. I don't recall any major cities or capitals named after the moon. Maybe in some fictional universe or science fiction, there's a city called the Moon Capital, but I don't have any information on that.\n",
      "\n",
      "So, putting it all together, the question might be trying to trick me into thinking about Earth's capitals, but since the moon isn't a planet, it doesn't have a capital. Alternatively, it could be a play on words where \" moons\" is the answer, but that doesn't make sense in a literal sense.\n",
      "\n",
      "I think the best answer is that there isn't a capital of the moon because it's a celestial body without the physical structure of a planet or a city. Maybe the question is trying to make me think about capital cities in a different context, but that's a stretch.\n",
      "\n",
      "I should probably stick with the straightforward answer: there is no capital of the moon because it's a moon, not a planet or a city. So, the answer is that there isn't a capital, or it doesn't exist.\n",
      "</think>\n",
      "\n",
      "The question of the capital of the moon is a trick question because the moon is a celestial body, not a planet or a city. Since it lacks the physical structure of a planet or a city, it does not have a capital. Therefore, the answer is that there is no capital of the moon.<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>What is the capital of the moon?<｜Assistant｜><think>\n",
      "Okay, so I need to figure\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0, : 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: <｜begin▁of▁sentence｜>\n",
      "1: <｜User｜>\n",
      "2: What\n",
      "3:  is\n",
      "4:  the\n",
      "5:  capital\n",
      "6:  of\n",
      "7:  the\n",
      "8:  moon\n",
      "9: ?\n",
      "10: <｜Assistant｜>\n",
      "11: <think>\n",
      "12: \n",
      "\n",
      "13: Okay\n",
      "14: ,\n",
      "15:  so\n",
      "16:  I\n",
      "17:  need\n",
      "18:  to\n",
      "19:  figure\n"
     ]
    }
   ],
   "source": [
    "# print a token-idx map of the first 20 tokens\n",
    "\n",
    "for i, token in enumerate(outputs[0, : 20]):\n",
    "    print(f\"{i}: {tokenizer.decode(token)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
