#!/usr/bin/env python3
import argparse
import os
import sys
import signal
import multiprocessing
from multiprocessing import Process
import torch
from vllm.utils import get_open_port
from datetime import datetime
from rich.panel import Panel

from model_filtering.utils import console
from model_filtering.pipeline import DifficultyFilterPipeline

# --------------------------------------------------------------------------- #
# Data-parallel worker                                                        #
# --------------------------------------------------------------------------- #
def run_dp_worker(args, dp_rank, dp_size):
    gpu_offset = dp_rank * args.tp_size
    os.environ["CUDA_VISIBLE_DEVICES"] = ",".join(str(gpu_offset + i) for i in range(args.tp_size))
    torch.cuda.set_device(0)

    os.environ.update(
        {
            "VLLM_DP_RANK": str(dp_rank),
            "VLLM_DP_RANK_LOCAL": str(dp_rank),
            "VLLM_DP_SIZE": str(dp_size),
            "VLLM_DP_MASTER_IP": args.master_addr,
            "VLLM_DP_MASTER_PORT": str(args.master_port),
            "VLLM_WORKER_MULTIPROC_METHOD": "spawn",
            "VLLM_USE_TORCH_DIST": "1",
        }
    )
    console.print(f"[DP rank {dp_rank}] sees {torch.cuda.device_count()} visible GPU(s).")

    args.dp_rank = dp_rank
    args.dp_size = dp_size

    console.rule(f"[bold]Worker Configuration DP {dp_rank}/{dp_size-1}", style="cyan")
    console.print(
        Panel(
            f"[bold]Model:[/bold] {args.model_path}\n"
            f"[bold]Dataset:[/bold] {args.dataset_parquet_path}\n"
            f"[bold]Batch size:[/bold] {args.batch_size}\n"
            f"[bold]Generations:[/bold] {args.n}\n"
            f"[bold]Max tokens:[/bold] {args.max_new_tokens}\n"
            f"[bold]Reward workers:[/bold] {args.reward_workers}\n"
            f"[bold]Tensor parallel:[/bold] {args.tp_size}",
            title="ðŸ“‹ Configuration",
            border_style="cyan",
        )
    )

    DifficultyFilterPipeline(args).run_inference()

# --------------------------------------------------------------------------- #
# CLI / launcher                                                              #
# --------------------------------------------------------------------------- #
def main():
    def handle_signal(signum, _):
        console.print(f"\nâš ï¸ [warning]Received signal {signum}, shutting downâ€¦[/warning]")
        sys.exit(1)

    signal.signal(signal.SIGINT, handle_signal)
    signal.signal(signal.SIGTERM, handle_signal)

    parser = argparse.ArgumentParser(description="Difficulty filtering using verl reward functions")
    parser.add_argument("--model_path", type=str, required=True)
    parser.add_argument("--dataset_parquet_path", type=str, required=True)
    parser.add_argument("--output_dir", type=str, default="./diff_filter_output")

    parser.add_argument("--max_prompt_length", type=int, default=2048)
    parser.add_argument(
        "--truncation", type=str, default="error", choices=["left", "right", "error"]
    )
    parser.add_argument("--default_data_source", type=str, default="None")
    parser.add_argument("--correct_reward_threshold", type=float, default=1.0)

    parser.add_argument("--batch_size", type=int, default=4)
    parser.add_argument("--n", type=int, default=16)
    parser.add_argument("--max_new_tokens", type=int, default=2048)
    parser.add_argument("--top_k", type=int, default=100)
    parser.add_argument("--top_p", type=float, default=0.9)
    parser.add_argument("--temperature", type=float, default=1.0)
    parser.add_argument("--repetition_penalty", type=float, default=1.0)

    parser.add_argument("--checkpoint_freq", type=int, default=5)
    parser.add_argument("--debug", action="store_true")
    parser.add_argument("--reward_workers", type=int, default=16)

    parser.add_argument("--dp_size", type=int, default=1)
    parser.add_argument("--tp_size", type=int, default=1)
    parser.add_argument("--node_size", type=int, default=1)
    parser.add_argument("--node_rank", type=int, default=0)
    parser.add_argument("--master_addr", type=str, default="127.0.0.1")
    parser.add_argument("--master_port", type=int, default=0)

    args = parser.parse_args()

    console.rule("[bold]Difficulty Filter Pipeline", style="cyan")
    console.print(f"â° Start time: {datetime.now():%Y-%m-%d %H:%M:%S}")
    console.rule(style="cyan")

    os.makedirs(args.output_dir, exist_ok=True)
    multiprocessing.set_start_method("spawn", force=True)
    os.environ["VLLM_WORKER_MULTIPROC_METHOD"] = "spawn"

    if args.node_size == 1:
        args.master_port = get_open_port()
    else:
        assert args.master_addr != "127.0.0.1"
        assert args.master_port > 0

    assert args.dp_size % args.node_size == 0
    dp_per_node = args.dp_size // args.node_size

    if args.dp_size == 1:
        run_dp_worker(args, dp_rank=0, dp_size=1)
    else:
        procs = []
        console.print(f"ðŸ”„ Starting {dp_per_node} worker(s) on node {args.node_rank}/{args.node_size-1}")
        for local_rank in range(dp_per_node):
            global_rank = args.node_rank * dp_per_node + local_rank
            p = Process(target=run_dp_worker, args=(args, global_rank, args.dp_size))
            p.start()
            procs.append(p)

        exit_code = 0
        for p in procs:
            p.join()
            if p.exitcode not in (None, 0):
                exit_code = p.exitcode or 1
        sys.exit(exit_code)


if __name__ == "__main__":
    main()